{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a23b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8561fbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 21:43:58.605689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:43:58.606027: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-01-01 21:44:01.447151: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:44:02.906649: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:44:02.906771: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:44:02.906839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:44:02.906899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:44:02.949081: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:44:02.949208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2026-01-01 21:44:02.949221: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from models.snn.factory import build_snn\n",
    "from models.snn.train import train_model, evaluate_model\n",
    "from models.snn.tuning import tune_hyperparameters\n",
    "from models.preprocessing import load_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b7c2739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train: X=(247, 614400), y=(247, 10)\n",
      "Loaded val: X=(71, 614400), y=(71, 10)\n",
      "Loaded test: X=(36, 614400), y=(36, 10)\n",
      "Loaded class names: ['benjamin', 'christian', 'felix', 'jonas', 'leon', 'mark', 'marvin', 'ohman', 'veronica', 'yannes']\n"
     ]
    }
   ],
   "source": [
    "splits, class_names = load_preprocessed('../../data/processed/')\n",
    "X_train, y_train = splits['train']\n",
    "X_val, y_val = splits['val']\n",
    "X_test, y_test = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf87b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = Path('../../checkpoints/snn')\n",
    "env_path = str((checkpoint_dir / \"best_hparams.env\").absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb9fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ray Tune] Initializing Ray runtime...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 21:44:06,272\tINFO worker.py:1927 -- Started a local Ray instance.\n",
      "2026-01-01 21:44:06,643\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ray Tune] Preparing hyperparameter search...\n",
      "  max_epochs      = 5\n",
      "  num_samples     = 20\n",
      "  project_name    = snn_ray_tune\n",
      "[Ray Tune] Starting tuning run...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":job_id:01000000\n",
      ":task_name:bundle_reservation_check_func\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":job_id:01000000\n",
      ":task_name:bundle_reservation_check_func\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":actor_name:ImplicitFunc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":actor_name:ImplicitFunc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":actor_name:_ray_trainable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":actor_name:_ray_trainable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[Ray Tune] Starting trial with configuration:\n",
      "  hidden=168\n",
      "  synapse_fast=0.0034597789971448126\n",
      "  synapse_slow=0.0548257326810924\n",
      "  learning_rate=5.05e-04\n",
      "  batch_size=64\n",
      "  epochs=5\n",
      "Creating simulator...\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raah/.local/share/virtualenvs/neuro-ai-9gzpYvh7/lib/python3.10/site-packages/nengo_dl/simulator.py:456: UserWarning: No GPU support detected. See https://www.nengo.ai/nengo-dl/installation.html#installing-tensorflow for instructions on setting up TensorFlow with GPU support.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|######               Building network (10%)                     | ETA: 0:00:06\n",
      "|######               Building network (10%)                     | ETA: 0:00:07\n",
      "|######               Building network (10%)                     | ETA: 0:00:07\n",
      "|######               Building network (10%)                     | ETA: 0:00:08\n",
      "|#####################Building network (40%)                     | ETA: 0:00:01\n",
      "|#####################Building network (40%)                     | ETA: 0:00:01\n",
      "|#####################Building network (40%)                     | ETA: 0:00:01\n",
      "|#####################Building network (40%)                     | ETA: 0:00:01\n",
      "|#####################Building network (50%)                     | ETA: 0:00:01\n",
      "|#####################Building network (50%)                     | ETA: 0:00:01\n",
      "|#####################Building network (60%)                     | ETA: 0:00:00\n",
      "|#####################Building network (60%)                     | ETA: 0:00:00\n",
      "|#####################Building network (60%)                     | ETA: 0:00:00\n",
      "|#####################Building network (60%)                     | ETA: 0:00:00\n",
      "|#####################Building network (70%)#                    | ETA: 0:00:00\n",
      "|#####################Building network (70%)#                    | ETA: 0:00:00\n",
      "|#####################Building network (70%)#                    | ETA: 0:00:00\n",
      "Build finished in 0:00:01\n",
      "|#                         Optimizing graph                           | 0:00:00\n",
      "|#             Optimizing graph: operator simplificaton               | 0:00:00\n",
      "| #                        Optimizing graph                           | 0:00:00\n",
      "Optimizing graph: operator simplificaton finished in 0:00:00\n",
      "|#                Optimizing graph: merging operators                 | 0:00:00\n",
      "Optimizing graph: merging operators finished in 0:00:00\n",
      "|#                Optimizing graph: ordering signals                  | 0:00:00\n",
      "Optimizing graph: ordering signals finished in 0:00:00\n",
      "|#                Optimizing graph: creating signals                  | 0:00:00\n",
      "Optimizing graph: creating signals finished in 0:00:00\n",
      "Optimization finished in 0:00:00\n",
      "|#                        Constructing graph                          | 0:00:00\n",
      "| #                       Constructing graph                          | 0:00:00\n",
      "|  #                      Constructing graph                          | 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 21:46:43.099291: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2026-01-01 21:46:43.099663: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-PH8A95A): /proc/driver/nvidia/version does not exist\n",
      "2026-01-01 21:46:43.100521: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     #                   Constructing graph                          | 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|####          Constructing graph: build stage (7%)              | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (35%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (64%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (85%)###          | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|        #                Constructing graph                          | 0:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "Construction finished in 0:00:00\n",
      "Compiling model...\n",
      "\n",
      "Training for 5 epochs...\n",
      "  Input shape: (247, 1, 614400)\n",
      "  Label shape: (247, 1, 10)\n",
      "Epoch 1/5\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raah/.local/share/virtualenvs/neuro-ai-9gzpYvh7/lib/python3.10/site-packages/nengo_dl/simulator.py:1003: UserWarning: Running for one timestep, but the network contains synaptic filters (which will introduce at least a one-timestep delay); did you mean to set synapse=None?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|####          Constructing graph: build stage (7%)              | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (35%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (50%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (71%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|####          Constructing graph: build stage (7%)              | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (35%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (57%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (78%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "247/247 [==============================] - 80s 311ms/step - loss: 2.3026 - probe_loss: 2.3026 - probe_accuracy: 0.0607\n",
      "Epoch 2/5\n",
      "247/247 [==============================] - 76s 309ms/step - loss: 2.3026 - probe_loss: 2.3026 - probe_accuracy: 0.0607\n",
      "Epoch 3/5\n",
      "247/247 [==============================] - 76s 309ms/step - loss: 2.3026 - probe_loss: 2.3026 - probe_accuracy: 0.0607\n",
      "Epoch 4/5\n",
      " 42/247 [====>.........................] - ETA: 1:07 - loss: 2.3026 - probe_loss: 2.3026 - probe_accuracy: 0.0476"
     ]
    }
   ],
   "source": [
    "best_config, analysis = tune_hyperparameters(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    n_features=X_train.shape[1],\n",
    "    n_classes=len(class_names),\n",
    "    max_epochs=5,\n",
    "    num_samples=20,\n",
    "    project_name=\"snn_ray_tune\",\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters found by Ray Tune:\n",
      "\n",
      "  Hidden neurons: 167\n",
      "  Synapse fast: 0.0044048588944318855\n",
      "  Synapse slow: 0.05422395713610029\n",
      "  Learning rate: 1.10e-03\n",
      "  Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest hyperparameters found by Ray Tune:\\n\")\n",
    "print(f\"  Hidden neurons: {best_config['n_neurons_hidden']}\")\n",
    "print(f\"  Synapse fast: {best_config.get('synapse_fast')}\")\n",
    "print(f\"  Synapse slow: {best_config.get('synapse_slow')}\")\n",
    "print(f\"  Learning rate: {best_config['learning_rate']:.2e}\")\n",
    "print(f\"  Batch size: {best_config['batch_size']}\")\n",
    "\n",
    "best_hidden = int(best_config['n_neurons_hidden'])\n",
    "best_syn_fast = float(best_config.get('synapse_fast'))\n",
    "best_syn_slow = float(best_config.get('synapse_slow'))\n",
    "best_lr = float(best_config['learning_rate'])\n",
    "best_batch_sz = int(best_config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4473c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving best hyperparameters to /home/z003dy4u/repos/neuroAi/notebooks/snn/../../checkpoints/snn/best_hparams.env ...\n",
      "Best hyperparameters saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSaving best hyperparameters to {env_path} ...\")\n",
    "with open(env_path, \"w\") as f:\n",
    "    f.write(f\"N_NEURONS_HIDDEN={best_hidden}\\n\")\n",
    "    f.write(f\"SYNAPSE_FAST={best_syn_fast}\\n\")\n",
    "    f.write(f\"SYNAPSE_SLOW={best_syn_slow}\\n\")\n",
    "    f.write(f\"LEARNING_RATE={best_lr}\\n\")\n",
    "    f.write(f\"BATCH_SIZE={best_batch_sz}\\n\")\n",
    "    f.write(f\"N_FEATURES={X_train.shape[1]}\\n\")\n",
    "    f.write(f\"N_CLASSES={len(class_names)}\\n\")\n",
    "print(\"Best hyperparameters saved.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro-ai-9gzpYvh7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
